# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yhUV-P4IlIvCg-wZ-7XFr5fi20APTO5A
"""

import tensorflow as tf
from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPooling2D, Add, GlobalAveragePooling2D, Dense
from tensorflow.keras.models import Model
from tensorflow.keras.preprocessing.image import ImageDataGenerator #NHWC -> NCHW
from tensorflow.keras.applications.resnet_v2 import preprocess_input, decode_predictions
import time



def conv_block(filters, kernel_size, strides=(1, 1), padding='same'):
    layers_conv_block = []
    l_Conv2D = Conv2D(filters, kernel_size, strides=strides, padding=padding)
    layers_conv_block.append(l_Conv2D)
    l_BatchNormalization = BatchNormalization()
    layers_conv_block.append(l_BatchNormalization)
    l_Activation = Activation('relu')
    layers_conv_block.append(l_Activation)
    return layers_conv_block

def identity_block(filters, kernel_size):
    layers_identity_block = []
    x = conv_block(filters, kernel_size)
    layers_identity_block.append(x[0])
    layers_identity_block.append(x[1])
    layers_identity_block.append(x[2])
    x = Conv2D(filters, kernel_size, padding='same')
    layers_identity_block.append(x)
    x = BatchNormalization()
    layers_identity_block.append(x)
    x = Activation('relu')
    layers_identity_block.append(x)
    x = Conv2D(filters, kernel_size, padding='same')
    layers_identity_block.append(x)
    x = BatchNormalization()
    layers_identity_block.append(x)
    #x = Add()([x, inputs])
    #layers_identity_block.append(x)
    x = Activation('relu')
    layers_identity_block.append(x)
    return layers_identity_block




#def identity_block_time(capa_ident):
#    layers_identity_time = []
#    x = conv_block(filters, kernel_size)
#    layers_identity_block.append(x[0])
#    layers_identity_block.append(x[1])
#    layers_identity_block.append(x[2])
#    x = Conv2D(filters, kernel_size, padding='same')
#    layers_identity_block.append(x)
#    x = BatchNormalization()
#    layers_identity_block.append(x)
#    x = Activation('relu')
#    layers_identity_block.append(x)
#    x = Conv2D(filters, kernel_size, padding='same')
#    layers_identity_block.append(x)
#    x = BatchNormalization()
#    layers_identity_block.append(x)
    #x = Add()([x, inputs])
    #layers_identity_block.append(x)
#    x = Activation('relu')
#    layers_identity_block.append(x)
#    return layers_identity_block


def resnet50v2(input_shape=(224, 224, 3), num_classes=2):
    inputs = Input(shape=input_shape)
    t_activation = 0.0
    t_conv2D = 0.0
    t_batchNormalization = 0.0
    t_maxPool2D = 0.0
    layers_conv_block = []
    layers_identity_block = []

    input_shape = (256, 224, 224, 3)
#Block 1
    x = conv_block(64, (7, 7), strides=(2, 2), padding='same')
    layers_conv_block.append(x)

    layers_MaxPooling2D = MaxPooling2D((3, 3), strides=(2, 2), padding='same')

    layers_identity_block.append(identity_block(64, (3, 3)))
    layers_identity_block.append(identity_block(64, (3, 3)))
    layers_identity_block.append(identity_block(64, (3, 3)))

#Block 2

    x = conv_block(128, (1, 1), strides=(2, 2))
    layers_conv_block.append(x)

    layers_identity_block.append(identity_block(128, (3, 3)))
    layers_identity_block.append(identity_block(128, (3, 3)))
    layers_identity_block.append(identity_block(128, (3, 3)))

#Block 3

    x = conv_block(256, (1, 1), strides=(2, 2))
    layers_conv_block.append(x)

    layers_identity_block.append(identity_block(256, (3, 3)))
    layers_identity_block.append(identity_block(256, (3, 3)))
    layers_identity_block.append(identity_block(256, (3, 3)))
    layers_identity_block.append(identity_block(256, (3, 3)))
    layers_identity_block.append(identity_block(256, (3, 3)))


#Block 4

    x = conv_block(512, (1, 1), strides=(2, 2))
    layers_conv_block.append(x)

    layers_identity_block.append(identity_block(512, (3, 3)))
    layers_identity_block.append(identity_block(512, (3, 3)))

    layers_GlobalAveragePooling2D = GlobalAveragePooling2D()
    layers_Dense = Dense(num_classes, activation='softmax')

    #model = Model(inputs, layers_Dense)


    t0 = time.time()
    out = layers_conv_block[0][0](single_image_generator)
    t_conv2D += time.time() - t0

    t0 = time.time()
    out = layers_conv_block[0][1](out)
    t_batchNormalization += time.time() - t0

    t0 = time.time()
    out = layers_conv_block[0][2](out)
    t_activation += time.time() - t0

    t0 = time.time()
    out = layers_MaxPooling2D(out)
    t_maxPool2D += time.time() - t0

    t_total = t_conv2D + t_batchNormalization + t_activation + t_maxPool2D

    print("  Conv2D    : [%.6f(s)] (%.2f%%)" % (t_conv2D,    t_conv2D    * 100.0 / t_total))
    print("  BatchNorma: [%.6f(s)] (%.2f%%)" % (t_batchNormalization, t_batchNormalization * 100.0 / t_total))
    print("  Activacion: [%.6f(s)] (%.2f%%)" % (t_activation, t_activation * 100.0 / t_total))
    print("  MaxPool2D : [%.6f(s)] (%.2f%%)" % (t_maxPool2D, t_maxPool2D * 100.0 / t_total))
    #return model

# Crear la instancia del modelo ResNet50V2
#model =
resnet50v2()

# Imprimir el resumen del modelo
#model.summary()

#model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])
#train_datagen = ImageDataGenerator(rescale=1./255)
#single_image_generator = train_datagen.flow_from_directory('./data', target_size=(224, 224), batch_size=1, class_mode='categorical', subset='training', shuffle=False)


# Entrenar el modelo con una sola imagen

#model.fit(single_image_generator, epochs=1)

# Guardar los pesos entrenados del modelo
#model.save_weights('resnet50_weights.h5')

import tensorflow as tf
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, AveragePooling2D, Flatten, Dense, Dropout, concatenate

def inception_module(x, filters):
    conv1x1 = Conv2D(filters[0], (1, 1), padding='same', activation='relu')(x)

    conv3x3_reduce = Conv2D(filters[1], (1, 1), padding='same', activation='relu')(x)
    conv3x3 = Conv2D(filters[2], (3, 3), padding='same', activation='relu')(conv3x3_reduce)

    conv5x5_reduce = Conv2D(filters[3], (1, 1), padding='same', activation='relu')(x)
    conv5x5 = Conv2D(filters[4], (5, 5), padding='same', activation='relu')(conv5x5_reduce)

    maxpool = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(x)
    maxpool_proj = Conv2D(filters[5], (1, 1), padding='same', activation='relu')(maxpool)

    inception_output = concatenate([conv1x1, conv3x3, conv5x5, maxpool_proj], axis=-1)
    return inception_output

def googlenet(input_shape=(224, 224, 3), num_classes=2):
    inputs = Input(shape=input_shape)

    x = Conv2D(64, (7, 7), strides=(2, 2), padding='same', activation='relu')(inputs)
    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)
    x = Conv2D(64, (1, 1), padding='same', activation='relu')(x)
    x = Conv2D(192, (3, 3), padding='same', activation='relu')(x)
    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)

    x = inception_module(x, [64, 96, 128, 16, 32, 32]) # Inception 3a
    x = inception_module(x, [128, 128, 192, 32, 96, 64]) # Inception 3b
    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)

    x = inception_module(x, [192, 96, 208, 16, 48, 64]) # Inception 4a
    x = inception_module(x, [160, 112, 224, 24, 64, 64]) # Inception 4b
    x = inception_module(x, [128, 128, 256, 24, 64, 64]) # Inception 4c
    x = inception_module(x, [112, 144, 288, 32, 64, 64]) # Inception 4d
    x = inception_module(x, [256, 160, 320, 32, 128, 128]) # Inception 4e
    x = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)

    x = inception_module(x, [256, 160, 320, 32, 128, 128]) # Inception 5a
    x = inception_module(x, [384, 192, 384, 48, 128, 128]) # Inception 5b

    x = AveragePooling2D((7, 7))(x)
    x = Flatten()(x)
    x = Dropout(0.4)(x)
    x = Dense(num_classes, activation='softmax')(x)

    model = tf.keras.Model(inputs, x, name='googlenet')
    return model

# Crear la instancia del modelo GoogleLeNet
model = googlenet()

# Imprimir el resumen del modelo
model.summary()

import sys
import os
os.environ["CUDA_VISIBLE_DEVICES"] = "-1"
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'

import tensorflow as tf
import time

def vgg16():
    #inputs = Input(shape=input_shape)
    tf.config.threading.set_intra_op_parallelism_threads(1)
    #Timers Initialization
    t_conv2D    = 0.0
    t_maxPool2D = 0.0
    t_flatten   = 0.0
    t_dense     = 0.0
    t_dropout   = 0.0

    #(Batch_size (N), Hight (H), Width (W), Channels (C)) #NHWC
    input_shape = (256, 224, 224, 3)

    #Create Input Tensor
    inputs = tf.random.normal(input_shape);


    # Block 1
    l_conv2D_1 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')
    l_conv2D_2 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')
    l_maxPool2D_1 = tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2))

    # Block 2
    l_conv2D_3 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')
    l_conv2D_4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')
    l_maxPool2D_2 = tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2))

    # Block 3
    l_conv2D_5 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same')
    l_conv2D_6 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same')
    l_conv2D_7 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same')
    l_maxPool2D_3 = tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2))

    # Block 4
    l_conv2D_8 = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same')
    l_conv2D_9 = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same')
    l_conv2D_10 = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same')
    l_maxPool2D_4 = tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2))

    # Block 5
    l_conv2D_11 = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same')
    l_conv2D_12 = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same')
    l_conv2D_13 = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same')
    l_maxPool2D_5 = tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2))

    # Classifier
    l_flatten = tf.keras.layers.Flatten()
    l_dense_1 = tf.keras.layers.Dense(4096, activation='relu')
    l_dropout_1 = tf.keras.layers.Dropout(0.5)
    l_dense_2 = tf.keras.layers.Dense(4096, activation='relu')
    l_dropout_2 = tf.keras.layers.Dropout(0.5)
    l_dense_3 = tf.keras.layers.Dense(1000, activation='softmax')




    #---------------------------------------------------------------
    # CNN Arquitecture
    #---------------------------------------------------------------
    #Block 1
    t0 = time.time()
    out = l_conv2D_1(inputs)
    t_conv2D += time.time() - t0

    t0 = time.time()
    out = l_conv2D_2(out)
    t_conv2D += time.time() - t0

    t0 = time.time()
    out = l_maxPool2D_1(out)
    t_maxPool2D += time.time() - t0

    #Block 2

    t0 = time.time()
    out = l_conv2D_3(out)
    t_conv2D += time.time() - t0

    t0 = time.time()
    out = l_conv2D_4(out)
    t_conv2D += time.time() - t0

    t0 = time.time()
    out = l_maxPool2D_2(out)
    t_maxPool2D += time.time() - t0

    #Block 3

    t0 = time.time()
    out = l_conv2D_5(out)
    t_conv2D += time.time() - t0

    t0 = time.time()
    out = l_conv2D_6(out)
    t_conv2D += time.time() - t0

    t0 = time.time()
    out = l_conv2D_7(out)
    t_conv2D += time.time() - t0

    t0 = time.time()
    out = l_maxPool2D_3(out)
    t_maxPool2D += time.time() - t0

    #Block 4

    t0 = time.time()
    out = l_conv2D_8(out)
    t_conv2D += time.time() - t0

    t0 = time.time()
    out = l_conv2D_9(out)
    t_conv2D += time.time() - t0

    t0 = time.time()
    out = l_conv2D_10(out)
    t_conv2D += time.time() - t0

    t0 = time.time()
    out = l_maxPool2D_4(out)
    t_maxPool2D += time.time() - t0

    #Block 5

    t0 = time.time()
    out = l_conv2D_11(out)
    t_conv2D += time.time() - t0

    t0 = time.time()
    out = l_conv2D_12(out)
    t_conv2D += time.time() - t0

    t0 = time.time()
    out = l_conv2D_13(out)
    t_conv2D += time.time() - t0

    t0 = time.time()
    out = l_maxPool2D_5(out)
    t_maxPool2D += time.time() - t0

    #Classifier
    t0 = time.time()
    out = l_flatten(out)
    t_flatten += time.time() - t0

    t0 = time.time()
    out = l_dense_1(out)
    t_dense += time.time() - t0

    t0 = time.time()
    out = l_dropout_1(out)
    t_dropout += time.time() - t0

    t0 = time.time()
    out = l_dense_2(out)
    t_dense += time.time() - t0

    t0 = time.time()
    out = l_dropout_2(out)
    t_dropout += time.time() - t0

    t0 = time.time()
    out = l_dense_3(out)
    t_dense += time.time() - t0


    t_total = t_conv2D + t_maxPool2D + t_flatten + t_dense + t_dropout
    #---------------------------------------------------------------

    print("  Conv2D   : [%.6f(s)] (%.2f%%)" % (t_conv2D,    t_conv2D    * 100.0 / t_total))
    print("  MaxPool2D: [%.6f(s)] (%.2f%%)" % (t_maxPool2D, t_maxPool2D * 100.0 / t_total))
    print("  Flatten  : [%.6f(s)] (%.2f%%)" % (t_flatten,   t_flatten   * 100.0 / t_total))
    print("  Dense    : [%.6f(s)] (%.2f%%)" % (t_dense,     t_dense     * 100.0 / t_total))
    print("  Dropout  : [%.6f(s)] (%.2f%%)" % (t_dropout,   t_dropout   * 100.0 / t_total))
    print("-----------------------------------------------")
    print("  Total    : [%.6f(s)]" % (t_total))
    print("-----------------------------------------------")



def main():
    print("Starting Tensorflow Profiling for Vgg16_Imagenet...\n")
    vgg16()
    #model.summary()


if __name__ == '__main__':
    sys.exit(main())
# Crear la instancia del modelo VGG16

import sys
import os
os.environ["CUDA_VISIBLE_DEVICES"] = "-1"
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'

import tensorflow as tf
import time


def alexnet_imagenet():

    #Fix Number of Threads
    tf.config.threading.set_intra_op_parallelism_threads(1)

    #Timers Initialization
    t_conv2D    = 0.0
    t_maxPool2D = 0.0
    t_flatten   = 0.0
    t_dense     = 0.0
    t_dropout   = 0.0

    #(Batch_size (N), Hight (H), Width (W), Channels (C)) #NHWC
    input_shape = (256, 227, 227, 3)

    #Create Input Tensor
    inputs = tf.random.normal(input_shape);
    #inputs = tf.keras.layers.Input(shape=input_shape)

    #---------------------------------------------------------------
    # Classes Construction
    #---------------------------------------------------------------
    #Convolution2D
    l_conv2D_1 = tf.keras.layers.Conv2D(96, (11, 11), strides=(4, 4),
                 activation='relu', padding='valid')

    l_conv2D_2 = tf.keras.layers.Conv2D(256, (5, 5),
                 activation='relu', padding='same')

    l_conv2D_3 = tf.keras.layers.Conv2D(384, (3, 3),
                 activation='relu', padding='same')

    l_conv2D_4 = tf.keras.layers.Conv2D(384, (3, 3),
                 activation='relu', padding='same')

    l_conv2D_5 = tf.keras.layers.Conv2D(256, (3, 3),
                 activation='relu', padding='same')

    #MaxPool2D
    l_maxPool2D_1 = tf.keras.layers.MaxPooling2D((3, 3), strides=(2, 2))
    l_maxPool2D_2 = tf.keras.layers.MaxPooling2D((3, 3), strides=(2, 2))
    l_maxPool2D_3 = tf.keras.layers.MaxPooling2D((3, 3), strides=(2, 2))

    #Others
    l_flatten   = tf.keras.layers.Flatten()
    l_dense_1   = tf.keras.layers.Dense(4096, activation='relu')
    l_dropout_1 = tf.keras.layers.Dropout(0.5)
    l_dense_2   = tf.keras.layers.Dense(4096, activation='relu')
    l_dropout_2 = tf.keras.layers.Dropout(0.5)
    l_dense_3   = tf.keras.layers.Dense(1000, activation='softmax')
    #---------------------------------------------------------------


    #---------------------------------------------------------------
    # CNN Arquitecture
    #---------------------------------------------------------------
    #Block 1
    t0 = time.time()
    out = l_conv2D_1(inputs)
    t_conv2D += time.time() - t0

    t0 = time.time()
    out = l_maxPool2D_1(out)
    t_maxPool2D += time.time() - t0

    #Block 2
    t0 = time.time()
    out = l_conv2D_2(out)
    t_conv2D += time.time() - t0

    t0 = time.time()
    out = l_maxPool2D_2(out)
    t_maxPool2D += time.time() - t0

    #Block 3
    t0 = time.time()
    out = l_conv2D_3(out)
    t_conv2D += time.time() - t0

    #Block 4
    t0 = time.time()
    out = l_conv2D_4(out)
    t_conv2D += time.time() - t0

    #Block 5
    t0 = time.time()
    out = l_conv2D_5(out)
    t_conv2D += time.time() - t0

    t0 = time.time()
    out = l_maxPool2D_3(out)
    t_maxPool2D += time.time() - t0

    #Classifier
    t0 = time.time()
    out = l_flatten(out)
    t_flatten += time.time() - t0

    t0 = time.time()
    out = l_dense_1(out)
    t_dense += time.time() - t0

    t0 = time.time()
    out = l_dropout_1(out)
    t_dropout += time.time() - t0

    t0 = time.time()
    out = l_dense_2(out)
    t_dense += time.time() - t0

    t0 = time.time()
    out = l_dropout_2(out)
    t_dropout += time.time() - t0

    t0 = time.time()
    out = l_dense_3(out)
    t_dense += time.time() - t0

    t_total = t_conv2D + t_maxPool2D + t_flatten + t_dense + t_dropout
    #---------------------------------------------------------------

    print("  Conv2D   : [%.6f(s)] (%.2f%%)" % (t_conv2D,    t_conv2D    * 100.0 / t_total))
    print("  MaxPool2D: [%.6f(s)] (%.2f%%)" % (t_maxPool2D, t_maxPool2D * 100.0 / t_total))
    print("  Flatten  : [%.6f(s)] (%.2f%%)" % (t_flatten,   t_flatten   * 100.0 / t_total))
    print("  Dense    : [%.6f(s)] (%.2f%%)" % (t_dense,     t_dense     * 100.0 / t_total))
    print("  Dropout  : [%.6f(s)] (%.2f%%)" % (t_dropout,   t_dropout   * 100.0 / t_total))
    print("-----------------------------------------------")
    print("  Total    : [%.6f(s)]" % (t_total))
    print("-----------------------------------------------")

def main():
    print("Starting Tensorflow Profiling for AlexNet_Imagenet...\n")
    alexnet_imagenet()


if __name__ == '__main__':
    sys.exit(main())